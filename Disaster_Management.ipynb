{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIGHA_JAIN_SCAAI_PS-3",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuB3SSnEU3Ll"
      },
      "source": [
        "INSTALL KAGGLE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltylRNRTjqHF"
      },
      "source": [
        "! pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozf8qYM2kPcj"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrpOMFHtVbiE"
      },
      "source": [
        "IMPORT KAGGLE API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwhuT7k3kS-n"
      },
      "source": [
        "cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z05j5afbkVwT"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BdwEIgvkYdr"
      },
      "source": [
        "! kaggle datasets download varpit94/disaster-images-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3GXFquQViYk"
      },
      "source": [
        "IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI6VNtRnswkG"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.utils import class_weight \n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6mq5GWJ0jHs"
      },
      "source": [
        "! unzip disaster-images-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1-uZ1kyRcg-"
      },
      "source": [
        "os.listdir('Comprehensive Disaster Dataset(CDD)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx8c4r9eVzPW"
      },
      "source": [
        "CREATE DIRECTORIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yq1Wf1tGFiQ"
      },
      "source": [
        "os.mkdir(\"Training_set\")\n",
        "os.mkdir(\"Testing_set\")\n",
        "os.mkdir(\"Testing_set/Fire_Disaster\")\n",
        "os.mkdir(\"Testing_set/Damaged_Infrastructure\")\n",
        "os.mkdir(\"Testing_set/Human_Damage\")\n",
        "os.mkdir(\"Testing_set/Land_Disaster\")\n",
        "os.mkdir(\"Testing_set/Non_Damage\")\n",
        "os.mkdir(\"Testing_set/Water_Disaster\")\n",
        "os.mkdir(\"Training_set/Damaged_Infrastructure\")\n",
        "os.mkdir(\"Training_set/Human_Damage\")\n",
        "os.mkdir(\"Training_set/Land_Disaster\")\n",
        "os.mkdir(\"Training_set/Non_Damage\")\n",
        "os.mkdir(\"Training_set/Water_Disaster\")\n",
        "os.mkdir(\"Training_set/Fire_Disaster\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFk3F15lebwl"
      },
      "source": [
        "\n",
        "source = \"Comprehensive Disaster Dataset(CDD)/Fire_Disaster/Urban_Fire\"\n",
        "destination1 = \"Training_set/Fire_Disaster/\"\n",
        "destination2 = \"Testing_set/Fire_Disaster\"\n",
        "num_img_fire =0\n",
        "files = os.listdir(source)\n",
        "num_img_fire = num_img_fire+len(files)\n",
        "random.shuffle(files)\n",
        "cnt=0\n",
        "for file in files:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file) \n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=166:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file)\n",
        "    num_img_fire-=1\n",
        "\n",
        "source = \"Comprehensive Disaster Dataset(CDD)/Fire_Disaster/Wild_Fire\"\n",
        "destination = \"Comprehensive Disaster Dataset(CDD)/Fire_Disaster/\"\n",
        "\n",
        "files = os.listdir(source)\n",
        "num_img_fire = num_img_fire+len(files)\n",
        "cnt=0\n",
        "random.shuffle(files)\n",
        "for file in files:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file) \n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=204:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file)\n",
        "    num_img_fire-=1\n",
        "\n",
        "shutil.rmtree('Comprehensive Disaster Dataset(CDD)/Fire_Disaster/Wild_Fire')\n",
        "shutil.rmtree('Comprehensive Disaster Dataset(CDD)/Fire_Disaster/Urban_Fire')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iJrZdVnovJv"
      },
      "source": [
        "source = \"Comprehensive Disaster Dataset(CDD)/Damaged_Infrastructure/Earthquake\"\n",
        "destination1 = \"Training_set/Damaged_Infrastructure/\"\n",
        "destination2=\"Testing_set/Damaged_Infrastructure\"\n",
        "\n",
        "num_img_infra = 0\n",
        "\n",
        "files = os.listdir(source)\n",
        "num_img_infra = num_img_infra+len(files)\n",
        "cnt=0\n",
        "random.shuffle(files)\n",
        "for file in files:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file) \n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=14:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file)\n",
        "    num_img_infra-=1\n",
        "\n",
        "source = \"Comprehensive Disaster Dataset(CDD)/Damaged_Infrastructure/Infrastructure\"\n",
        "\n",
        "\n",
        "files = os.listdir(source)\n",
        "num_img_infra = num_img_infra+len(files)\n",
        "cnt=0\n",
        "random.shuffle(files)\n",
        "for file in files:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file) \n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=566:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file) \n",
        "    num_img_infra-=1\n",
        "\n",
        "shutil.rmtree(\"Comprehensive Disaster Dataset(CDD)/Damaged_Infrastructure/Infrastructure\")\n",
        "shutil.rmtree(\"Comprehensive Disaster Dataset(CDD)/Damaged_Infrastructure/Earthquake\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nZ7tSbnphCi"
      },
      "source": [
        "source = \"Comprehensive Disaster Dataset(CDD)/Land_Disaster/Drought\"\n",
        "destination1 = \"Training_set/Land_Disaster/\"\n",
        "destination2 = \"Testing_set/Land_Disaster\"\n",
        "num_img_land = 0\n",
        "cnt=0\n",
        "files = os.listdir(source)\n",
        "num_img_land = num_img_land+len(files)\n",
        "random.shuffle(files)\n",
        "for file in files:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file)\n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=80:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file)\n",
        "    num_img_land-=1 \n",
        "\n",
        "source = \"Comprehensive Disaster Dataset(CDD)/Land_Disaster/Land_Slide\"\n",
        "\n",
        "\n",
        "files = os.listdir(source)\n",
        "num_img_land = num_img_land+len(files)\n",
        "cnt=0\n",
        "random.shuffle(files)\n",
        "for file in files:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file) \n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=182:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file) \n",
        "    num_img_land-=1\n",
        "\n",
        "shutil.rmtree('Comprehensive Disaster Dataset(CDD)/Land_Disaster/Drought')\n",
        "shutil.rmtree('Comprehensive Disaster Dataset(CDD)/Land_Disaster/Land_Slide')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5AGqJeMzlCB"
      },
      "source": [
        "\n",
        "source = \"Comprehensive Disaster Dataset(CDD)/Non_Damage/Non_Damage_Buildings_Street\"\n",
        "destination1 = \"Training_set/Non_Damage\"\n",
        "destination2 = \"Testing_set/Non_Damage\"\n",
        "files = os.listdir(source)\n",
        "num_img_nodamage=0\n",
        "num_img_nodamage=num_img_nodamage+len(files)\n",
        "cnt=0\n",
        "random.shuffle(files)\n",
        "for file in files:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file)\n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=1830:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file)\n",
        "    num_img_buildings-=1\n",
        "\n",
        "\n",
        "source = \"Comprehensive Disaster Dataset(CDD)/Non_Damage/Non_Damage_Wildlife_Forest\"\n",
        "\n",
        "\n",
        "files = os.listdir(source)\n",
        "num_img_nodamage=num_img_nodamage+len(files)\n",
        "cnt=0\n",
        "random.shuffle(files)\n",
        "for file in files:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file)\n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=910:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file) \n",
        "    num_img_forest-=1\n",
        "\n",
        "source = \"Comprehensive Disaster Dataset(CDD)/Non_Damage/human\"\n",
        "\n",
        "\n",
        "files = os.listdir(source)\n",
        "num_img_nodamage=num_img_nodamage+len(files)\n",
        "cnt=0\n",
        "random.shuffle(files)\n",
        "for file in files:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file) \n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=48:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file) \n",
        "    num_img_human-=1\n",
        "\n",
        "\n",
        "source = \"Comprehensive Disaster Dataset(CDD)/Non_Damage/sea\"\n",
        "\n",
        "\n",
        "files = os.listdir(source)\n",
        "num_img_nodamage=num_img_nodamage+len(files)\n",
        "cnt=0\n",
        "random.shuffle(files)\n",
        "for file in files:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file) \n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=908:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file)\n",
        "    num_img_sea-=1 \n",
        "\n",
        "shutil.rmtree('Comprehensive Disaster Dataset(CDD)/Non_Damage/Non_Damage_Buildings_Street')\n",
        "shutil.rmtree('Comprehensive Disaster Dataset(CDD)/Non_Damage/Non_Damage_Wildlife_Forest')\n",
        "shutil.rmtree('Comprehensive Disaster Dataset(CDD)/Non_Damage/human')\n",
        "shutil.rmtree('Comprehensive Disaster Dataset(CDD)/Non_Damage/sea')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moprZjEnJyZM"
      },
      "source": [
        "source = \"Comprehensive Disaster Dataset(CDD)/Human_Damage\"\n",
        "destination1 = \"Training_set/Human_Damage\"\n",
        "destination2 = \"Testing_set/Human_Damage\"\n",
        "lst = os.listdir(source)\n",
        "num_img_damaged_by_human = len(lst)\n",
        "cnt=0\n",
        "random.shuffle(files)\n",
        "for file in lst:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file) \n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=96:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file) \n",
        "    os.remove(source+'/'+file)\n",
        "    num_img_damaged_by_human-=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyPA7qacK2_x"
      },
      "source": [
        "source = \"Comprehensive Disaster Dataset(CDD)/Water_Disaster\"\n",
        "destination1 = \"Training_set/Water_Disaster\"\n",
        "destination2 = \"Testing_set/Water_Disaster\"\n",
        "lst = os.listdir(source)\n",
        "num_img_water = len(lst)\n",
        "cnt=0\n",
        "random.shuffle(files)\n",
        "for file in lst:\n",
        "  try:\n",
        "    img = Image.open(source+'/'+file) \n",
        "    img.verify()\n",
        "    file_name = os.path.join(source, file)\n",
        "    cnt+=1\n",
        "    if cnt<=414:\n",
        "      shutil.move(file_name, destination2)\n",
        "    else:\n",
        "      shutil.move(file_name,destination1)\n",
        "  except (IOError) as e:\n",
        "    print('Bad file:', file) \n",
        "    os.remove(source+'/'+file)\n",
        "    num_img_water-=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov5pkAhgV31y"
      },
      "source": [
        "CURRENT DATA DISTRIBUTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBX7actc2AgX"
      },
      "source": [
        "print(\"Images of Damaged Infrastructure \\t\"+str(len(os.listdir(\"Training_set/Damaged_Infrastructure\"))))\n",
        "print(\"Images of Disaster by Fire  \\t \\t \"+str(len(os.listdir(\"Training_set/Fire_Disaster\"))))\n",
        "print(\"Images of Disaster by Land \\t \\t \"+str(len(os.listdir(\"Training_set/Land_Disaster\"))))\n",
        "print(\"Images of Disaster by Human \\t \\t\"+str(len(os.listdir(\"Training_set/Human_Damage\"))))\n",
        "print(\"Images of No Damage \\t\\t\\t\"+str(len(os.listdir(\"Training_set/Non_Damage\"))))\n",
        "print(\"Images of Disaster by Water\\t\\t\"+str(len(os.listdir(\"Training_set/Water_Disaster\"))))\n",
        "print(\"\\n\\n\\n\")\n",
        "disaster_count = dict()\n",
        "disaster_count[\"Damaged Infrastructure\"] = len(os.listdir(\"Training_set/Damaged_Infrastructure\"))\n",
        "disaster_count[\"Fire\"] = len(os.listdir(\"Training_set/Fire_Disaster\"))\n",
        "disaster_count[\"By Human\"] = len(os.listdir(\"Training_set/Human_Damage\"))\n",
        "disaster_count[\"Land\"] = len(os.listdir(\"Training_set/Land_Disaster\"))\n",
        "disaster_count[\"No Damage\"]=len(os.listdir(\"Training_set/Non_Damage\"))\n",
        "disaster_count[\"Water\"]=len(os.listdir(\"Training_set/Water_Disaster\"))\n",
        "plt.pie(disaster_count.values(),labels=disaster_count.keys(),autopct='%1.1f%%',radius=2,pctdistance=0.7)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAjT3nOQWNUT"
      },
      "source": [
        "DATA AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gVcEmVC0Qcz"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest',\n",
        "        brightness_range=[0.2,1.0])\n",
        "lst = os.listdir(\"Training_set/Human_Damage\")\n",
        "for f in lst:\n",
        "# print(f)\n",
        "  img = load_img(\"Training_set/Human_Damage/\"+f)  \n",
        "  x = img_to_array(img)  \n",
        "  x = x.reshape((1,) + x.shape)  \n",
        "  i = 0\n",
        "  for batch in datagen.flow(x,\n",
        "                          batch_size=1,save_to_dir=\"Training_set/Human_Damage/\", save_prefix=\"02\"+str(i), save_format='png'):\n",
        "    i += 1\n",
        "    if i > 5:\n",
        "        break \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK5YL5kXYAzJ"
      },
      "source": [
        "land_lst = os.listdir(\"Training_set/Land_Disaster\")\n",
        "for f in land_lst:\n",
        "  # print(f)\n",
        "  img = load_img(\"Training_set/Land_Disaster/\"+f)  \n",
        "  x = img_to_array(img)  \n",
        "  x = x.reshape((1,) + x.shape)  \n",
        "  i = 0\n",
        "  for batch in datagen.flow(x,\n",
        "                          batch_size=1,save_to_dir=\"Training_set/Land_Disaster/\", save_prefix=\"04\"+str(i), save_format='png'):\n",
        "    i += 1\n",
        "    if i > 1 :\n",
        "        break  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-waFcL6KbPHf"
      },
      "source": [
        "fire_lst = os.listdir(\"Training_set/Fire_Disaster\")\n",
        "for f in fire_lst:\n",
        "  # print(f)\n",
        "  img = load_img(\"Training_set/Fire_Disaster/\"+f)  \n",
        "  x = img_to_array(img)  \n",
        "  x = x.reshape((1,) + x.shape)  \n",
        "  i = 0\n",
        "  for batch in datagen.flow(x,\n",
        "                          batch_size=1,save_to_dir=\"Training_set/Fire_Disaster\", save_prefix=\"01\"+str(i), save_format='png'):\n",
        "    i += 1\n",
        "    if i > 1 :\n",
        "        break  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8pkUaS5bwoc"
      },
      "source": [
        "water_lst = os.listdir(\"Training_set/Water_Disaster\")\n",
        "random.shuffle(water_lst)\n",
        "for f in water_lst[:900]:\n",
        "  # print(f)\n",
        "  img = load_img(\"Training_set/Water_Disaster/\"+f)  \n",
        "  x = img_to_array(img)  \n",
        "  x = x.reshape((1,) + x.shape)  \n",
        "  i = 0\n",
        "  for batch in datagen.flow(x,\n",
        "                          batch_size=1,save_to_dir=\"Training_set/Water_Disaster\", save_prefix=\"03\"+str(i), save_format='png'):\n",
        "    i += 1\n",
        "    if i > 0 :\n",
        "        break \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0EaZz2UcE6b"
      },
      "source": [
        "\n",
        "\n",
        "infra_lst = os.listdir(\"Training_set/Damaged_Infrastructure\")\n",
        "random.shuffle(infra_lst)\n",
        "for f in infra_lst[:700]:\n",
        "  # print(f)\n",
        "  img = load_img(\"Training_set/Damaged_Infrastructure/\"+f) \n",
        "  if img.mode==\"CMYK\":\n",
        "      img = img.convert(\"RGB\")\n",
        "  x = img_to_array(img)  \n",
        "  x = x.reshape((1,) + x.shape)  \n",
        "  i = 0\n",
        "  for batch in datagen.flow(x,\n",
        "                          batch_size=1,save_to_dir=\"Training_set/Damaged_Infrastructure\", save_prefix=\"05\"+str(i), save_format='png'):\n",
        "    i += 1\n",
        "    if i > 0 :\n",
        "        break  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLGlr84RWiFl"
      },
      "source": [
        "CURRENT DATA DISTRIBUTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgomUYJTIqCZ"
      },
      "source": [
        "print(\"Images of Damaged Infrastructure \\t\"+str(len(os.listdir(\"Training_set/Damaged_Infrastructure\"))))\n",
        "print(\"Images of Disaster by Fire  \\t \\t \"+str(len(os.listdir(\"Training_set/Fire_Disaster\"))))\n",
        "print(\"Images of Disaster by Land \\t \\t \"+str(len(os.listdir(\"Training_set/Land_Disaster\"))))\n",
        "print(\"Images of Disaster by Human \\t \\t\"+str(len(os.listdir(\"Training_set/Human_Damage\"))))\n",
        "print(\"Images of No Damage \\t\\t\\t\"+str(len(os.listdir(\"Training_set/Non_Damage\"))))\n",
        "print(\"Images of Disaster by Water\\t\\t\"+str(len(os.listdir(\"Training_set/Water_Disaster\"))))\n",
        "print(\"\\n\\n\\n\")\n",
        "disaster_count = dict()\n",
        "disaster_count[\"Damaged Infrastructure\"] = len(os.listdir(\"Training_set/Damaged_Infrastructure\"))\n",
        "disaster_count[\"Fire\"] = len(os.listdir(\"Training_set/Fire_Disaster\"))\n",
        "disaster_count[\"By Human\"] = len(os.listdir(\"Training_set/Human_Damage\"))\n",
        "disaster_count[\"Land\"] = len(os.listdir(\"Training_set/Land_Disaster\"))\n",
        "disaster_count[\"No Damage\"]=len(os.listdir(\"Training_set/Non_Damage\"))\n",
        "disaster_count[\"Water\"]=len(os.listdir(\"Training_set/Water_Disaster\"))\n",
        "plt.pie(disaster_count.values(),labels=disaster_count.keys(),autopct='%1.1f%%',radius=2,pctdistance=0.7)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBdIwDBkO9ZN"
      },
      "source": [
        "data_gen_train = ImageDataGenerator(rescale=1./255)\n",
        "train_data_gen = data_gen_train.flow_from_directory(batch_size=100,\n",
        "                                              directory=\"Training_set\",\n",
        "                                              shuffle = True,\n",
        "                                              target_size = (128,128),\n",
        "                                              class_mode=\"sparse\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41cTMQOfhonH"
      },
      "source": [
        "train_data_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_E888xIhD9M"
      },
      "source": [
        "from sklearn.utils import class_weight \n",
        "import numpy as np\n",
        "weights = class_weight.compute_class_weight( 'balanced', np.unique(train_data_gen.classes), train_data_gen.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n__Soprlg2P9"
      },
      "source": [
        "weights = dict(enumerate(weights.flatten(), 0))\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irh1XskCqytN"
      },
      "source": [
        "data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.20)\n",
        "test_data_gen = data_gen.flow_from_directory(batch_size=100,\n",
        "                                              directory=\"Testing_set\",\n",
        "                                              shuffle = True,\n",
        "                                              target_size = (128,128),\n",
        "                                              subset='training',class_mode=\"sparse\")\n",
        "valid_data_gen = data_gen.flow_from_directory(batch_size=100,\n",
        "                                              directory=\"Testing_set\",\n",
        "                                              shuffle = True,\n",
        "                                              target_size = (128,128),\n",
        "                                              subset='validation',class_mode=\"sparse\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VzmS6OUWmIA"
      },
      "source": [
        "MODEL TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HlAuVdkL2XF"
      },
      "source": [
        "\n",
        "\n",
        "cnn = tf.keras.models.Sequential()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjgUIQnJgG3k"
      },
      "source": [
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[128, 128, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo5ish-WgWM5"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW_-hVuygfH4"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF4DJWO2ghby"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4D8eRfdgnTK"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=6, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVGOrni0gxZw"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = [\"accuracy\"])\n",
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJOfgja4IMy2"
      },
      "source": [
        "his = cnn.fit(train_data_gen, validation_data= valid_data_gen, steps_per_epoch = 64, epochs =8 ,class_weight=weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwX_TS9tY0Yq"
      },
      "source": [
        "ACCURACY AND LOSS GRAPH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v59SHucenG5"
      },
      "source": [
        "fig = plt.figure(figsize=(10,7))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=True)\n",
        "ax.plot(his.history['accuracy'], color='red')\n",
        "ax.plot(his.history['val_accuracy'], color ='green')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=True)\n",
        "ax.plot(his.history['loss'], color='red')\n",
        "ax.plot(his.history['val_loss'], color ='green')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwWx7A8SpDOT"
      },
      "source": [
        "\n",
        "loss_test, acc_test = cnn.evaluate(test_data_gen)\n",
        "\n",
        "print('\\nThe accuracy of the model is:', str(np.round(acc_test, 2)),'% for loss value',str(np.round(loss_test, 2)),'%.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT236D1gq0u2"
      },
      "source": [
        "y_pred = np.argmax(cnn.predict(test_data_gen),1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLR-1HToY-4H"
      },
      "source": [
        "CONFUSION MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4ZBjYWA_rZk"
      },
      "source": [
        "\n",
        "cm = confusion_matrix(test_data_gen.labels, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index = [\"Damaged_infrastructure\",\"Fire_Disaster\",\n",
        " 'Human_Damage',\n",
        " 'Land_Disaster',\n",
        " 'Non_Damage',\n",
        " 'Water_Disaster'],columns = [\"Damaged_infrastructure\",\"Fire_Disaster\",\n",
        " 'Human_Damage',\n",
        " 'Land_Disaster',\n",
        " 'Non_Damage',\n",
        " 'Water_Disaster'])\n",
        "plt.figure(figsize = (10,7))\n",
        "\n",
        "sns.heatmap(df_cm, annot=True,fmt='g',cmap=\"Blues\")\n",
        "plt.ylabel('Actual Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}